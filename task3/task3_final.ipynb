{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle optuna catboost\n",
        "!pip install -q xgboost --upgrade\n",
        "!pip install -q lightgbm --upgrade\n"
      ],
      "metadata": {
        "id": "RzTTgD3Z9bFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#import"
      ],
      "metadata": {
        "id": "dllsGocN9eFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostClassifier, CatBoostRegressor\n",
        "from sklearn.ensemble import VotingClassifier, StackingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import userdata\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "0RBxLhlH9k_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#preprocess"
      ],
      "metadata": {
        "id": "itdLeeGB9nKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(df_input):\n",
        "    \"\"\"\n",
        "    Applies imputation, feature engineering, and log transforms\n",
        "    exactly as per the original methodology.\n",
        "    \"\"\"\n",
        "    df = df_input.copy()\n",
        "\n",
        "    # Drop ID columns for training, but keep if needed later (handled outside)\n",
        "    df = df.drop(columns=['id', 'player_id'], errors='ignore')\n",
        "\n",
        "    # Identify types\n",
        "    numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "    # Filter out target from numeric_cols if it exists to avoid imputing it\n",
        "    if 'spending_30d' in numeric_cols:\n",
        "        numeric_cols = numeric_cols.drop('spending_30d')\n",
        "\n",
        "    # [cite_start]A. Impute Numerical with Median\n",
        "    for col in numeric_cols:\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            df[col] = df[col].fillna(df[col].median())\n",
        "\n",
        "    # [cite_start]B. Impute Categorical with Mode\n",
        "    for col in categorical_cols:\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            df[col] = df[col].fillna(df[col].mode()[0])\n",
        "        # Ensure proper type\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "    # [cite_start]C. Feature Engineering\n",
        "    # Use .get() to avoid errors if columns are missing\n",
        "    df['engagement_intensity'] = df.get('sessions_per_week', 0) * df.get('avg_session_length', 0)\n",
        "\n",
        "    # Added 1e-5 to avoid division by zero\n",
        "    df['spending_efficiency'] = df.get('historical_spending', 0) / (df.get('total_playtime_hours', 0) + 1e-5)\n",
        "\n",
        "    df['conversion_strength'] = df.get('total_transactions', 0) / (df.get('days_since_last_login', 0) + 1)\n",
        "\n",
        "    # [cite_start]D. Log Transform Skewed Features\n",
        "    skewed_feats = ['total_playtime_hours', 'historical_spending', 'avg_transaction_value']\n",
        "    for feat in skewed_feats:\n",
        "        if feat in df.columns:\n",
        "            df[f'log_{feat}'] = np.log1p(df[feat])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "Ahol3KcJ9mTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading and processing data\")\n",
        "train_file_path = \"/content/task3/train.csv\"\n",
        "test_file_path = \"/content/task3/test.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_file_path)\n",
        "df_test = pd.read_csv(test_file_path)\n",
        "test_player_ids = df_test['player_id']\n",
        "\n",
        "# start process Data\n",
        "df_train_processed = preprocess(df_train)\n",
        "df_test_processed = preprocess(df_test)\n",
        "\n",
        "target_class = 'will_spend'\n",
        "target_reg = 'log_target'\n",
        "\n",
        "df_train_processed[target_class] = (df_train_processed['spending_30d'] > 0).astype(int)\n",
        "df_train_processed[target_reg] = np.log1p(df_train_processed['spending_30d'])\n",
        "\n",
        "features_to_drop_regressor = [\n",
        "    'achievement_completion_rate', 'competitive_rank', 'games_played',\n",
        "    'days_since_last_login', 'cross_game_activity', 'seasonal_spending_pattern',\n",
        "    'account_age_days', 'primary_game', 'guild_membership'\n",
        "]\n",
        "\n",
        "all_features = [col for col in df_train_processed.columns\n",
        "                if col not in ['spending_30d', target_class, target_reg]]\n",
        "\n",
        "print(\"Encoding categorical features...\")\n",
        "combined = pd.concat([df_train_processed[all_features], df_test_processed[all_features]],\n",
        "                     axis=0, ignore_index=True)\n",
        "combined_encoded = pd.get_dummies(combined, drop_first=True)\n",
        "\n",
        "X_all = combined_encoded\n",
        "X_class = X_all.iloc[:len(df_train_processed)].reset_index(drop=True)\n",
        "X_test_all = X_all.iloc[len(df_train_processed):].reset_index(drop=True)\n",
        "\n",
        "y_class = df_train_processed[target_class]\n",
        "y_reg_full = df_train_processed[target_reg]\n",
        "\n",
        "print(\"Preparing regressor feature set...\")\n",
        "regressor_cols = [col for col in X_class.columns\n",
        "                  if not any(col.startswith(feat) for feat in features_to_drop_regressor)]\n",
        "\n",
        "features_classifier = X_class.columns.tolist()\n",
        "features_regressor = regressor_cols\n",
        "\n",
        "spenders_mask = (y_class == 1)\n",
        "X_reg = X_class.loc[spenders_mask, features_regressor].reset_index(drop=True)\n",
        "y_reg = y_reg_full.loc[spenders_mask].reset_index(drop=True)\n",
        "\n",
        "X_test_reg = X_test_all[features_regressor].reset_index(drop=True)\n",
        "print(\"preprocess done...\")"
      ],
      "metadata": {
        "id": "GLi0vhdE92lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLHr8XBLtQ7F"
      },
      "outputs": [],
      "source": [
        "# Soft Voting\n",
        "print(\"\\nTraining Classification Voting Ensemble...\")\n",
        "clf_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=500, learning_rate=0.05, max_depth=6,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    eval_metric='logloss',\n",
        "    device=\"cuda\",\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "clf_lgb = lgb.LGBMClassifier(\n",
        "    n_estimators=600, learning_rate=0.05, max_depth=-1, num_leaves=63,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    device_type=\"gpu\",\n",
        "    random_state=42, n_jobs=-1, verbose=-1\n",
        ")\n",
        "\n",
        "clf_cat = CatBoostClassifier(\n",
        "    n_estimators=500, learning_rate=0.05, depth=6,\n",
        "    loss_function='Logloss',\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    random_state=42, verbose=0\n",
        ")\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('xgb', clf_xgb), ('lgb', clf_lgb), ('cat', clf_cat)],\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_class, y_class)\n",
        "print(\"Classifier trained.\")\n",
        "\n",
        "# Regression Model Stacking - Only on Spenders\n",
        "print(\"\\nTraining Regression Stacking Ensemble...\")\n",
        "\n",
        "reg_xgb = xgb.XGBRegressor(\n",
        "    n_estimators=700, learning_rate=0.03, max_depth=6,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    objective='reg:squarederror', eval_metric='rmse',\n",
        "    device=\"cuda\",\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "reg_lgb = lgb.LGBMRegressor(\n",
        "    n_estimators=800, learning_rate=0.03, max_depth=-1, num_leaves=63,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    device_type=\"gpu\",\n",
        "    random_state=42, n_jobs=-1, verbose=-1\n",
        ")\n",
        "\n",
        "reg_cat = CatBoostRegressor(\n",
        "    n_estimators=700, learning_rate=0.03, depth=6,\n",
        "    loss_function='RMSE',\n",
        "    task_type=\"GPU\",\n",
        "    devices='0',\n",
        "    random_state=42, verbose=0\n",
        ")\n",
        "\n",
        "# Final Estimator for Stacking\n",
        "final_reg = xgb.XGBRegressor(\n",
        "    n_estimators=500, learning_rate=0.03, max_depth=6,\n",
        "    subsample=0.8, colsample_bytree=0.8,\n",
        "    objective='reg:squarederror',\n",
        "    device=\"cuda\",\n",
        "    random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "stack_reg = StackingRegressor(\n",
        "    estimators=[('xgb', reg_xgb), ('lgb', reg_lgb), ('cat', reg_cat)],\n",
        "    final_estimator=final_reg,\n",
        "    n_jobs=1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "stack_reg.fit(X_reg, y_reg)\n",
        "print(\"Regressor trained.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n final predictions...\")\n",
        "\n",
        "# Predict Probability of Spending (0 to 1)\n",
        "pred_class_proba = voting_clf.predict_proba(X_test_all)[:, 1]\n",
        "\n",
        "# Predict Log Amount (for EVERYONE in test)\n",
        "pred_reg_log = stack_reg.predict(X_test_reg)\n",
        "pred_reg_amount = np.expm1(pred_reg_log) # Reverse log transform\n",
        "\n",
        "# Clip negatives (regression artifacts)\n",
        "pred_reg_amount = np.maximum(pred_reg_amount, 0)\n",
        "\n",
        "#Combine: Expected Value = P(Spend) * Predicted Amount\n",
        "final_predictions = pred_class_proba * pred_reg_amount\n",
        "\n",
        "# Create Submission\n",
        "submission = pd.DataFrame({\n",
        "    'player_id': test_player_ids,\n",
        "    'spending_30d': final_predictions\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Success! 'submission.csv' has been created.\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "id": "6YmybQBT-5oO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}